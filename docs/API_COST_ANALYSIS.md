# API 사용 및 비용 분석

## 목차
1. [API 사용 지점 요약](#api-사용-지점-요약)
2. [워크플로우별 API 호출](#워크플로우별-api-호출)
3. [비용 예측](#비용-예측)
4. [비용 최적화 팁](#비용-최적화-팁)

---

## API 사용 지점 요약

### 1. 이벤트 Taxonomy 생성 (Excel 생성)
**파일**: `excel-schema-generator/src/taxonomy-builder-v2.ts`

#### API 호출 지점:
- **Stage 1**: 이벤트 및 공통 속성 생성
  - 호출 횟수: **1회**
  - 모델: `claude-sonnet-4-20250514` (기본값) 또는 설정된 모델
  - max_tokens: `8192`
  - 용도: 산업/시나리오 기반으로 이벤트 목록 생성

- **Stage 2**: 이벤트별 속성 생성 (배치 처리)
  - 호출 횟수: **ceil(이벤트 수 / 3)** 회
  - 배치 크기: 3개 이벤트씩 처리
  - 모델: `claude-sonnet-4-20250514`
  - max_tokens: `8192`
  - 배치 간 대기: 8초 (rate limit 방지)
  - 용도: 각 이벤트의 속성 정의

- **Stage 3**: 유저 데이터 스키마 생성
  - 호출 횟수: **1회**
  - 모델: `claude-sonnet-4-20250514`
  - max_tokens: `8192`
  - 용도: 유저 프로필 속성 정의

#### 예상 API 호출 수:
- 이벤트 20개: 1 + ceil(20/3) + 1 = **9회**
- 이벤트 40개: 1 + ceil(40/3) + 1 = **16회**
- 이벤트 60개: 1 + ceil(60/3) + 1 = **22회**
- 이벤트 100개: 1 + ceil(100/3) + 1 = **36회**

---

### 2. AI 분석 (Excel → AI 전략 분석)
**파일**: `data-generator/src/ai/client.ts`

#### 다단계 AI 분석 (Multi-Phase):

##### Phase 1: 전략 분석
- 호출 횟수: **1회**
- 모델: `claude-sonnet-4-20250514` (기본값)
- max_tokens: `8192` (재시도 시 최대 16384)
- 용도: 사용자 세그먼트, 이벤트 그룹핑, 세션 패턴 정의

##### Phase 1.5: 리텐션 커브 분석
- 호출 횟수: **1회 (Generator)**
- 검증 호출 (선택적):
  - Validator: `claude-haiku-4-5` (fast) 또는 `claude-sonnet-4-5` (balanced)
  - Fixer: 최대 3회 재시도
- max_tokens: `8192`
- 용도: 산업별 리텐션 커브 생성 및 검증

##### Phase 1.5a: 트랜잭션 감지
- 호출 횟수: **1회**
- 모델: `claude-sonnet-4-20250514`
- max_tokens: `8192`
- 용도: start/end 패턴 기반 트랜잭션 감지

##### Phase 1.6: 이벤트 순서 분석
- 호출 횟수: **1회 (Generator)**
- 검증 호출 (선택적):
  - Validator: `claude-haiku-4-5` (fast)
  - Fixer: 최대 3회 재시도
- max_tokens: `8192`
- 용도: 이벤트 의존성, 퍼널, 시퀀스 정의

##### Phase 2: 이벤트 그룹별 속성 범위 생성
- 호출 횟수: **그룹 수** (최대 5개 이벤트/그룹)
- 모델: `claude-sonnet-4-20250514`
- max_tokens: `8192`
- 그룹 간 대기: 1초
- 용도: 각 이벤트의 속성 값 범위 정의

#### 예상 API 호출 수:
- **최소 (검증 없음)**: 1 + 1 + 1 + 1 + 그룹수 = **4 + ceil(이벤트수/5)**
- **최대 (검증 실패 시)**: 1 + (1+4) + 1 + (1+4) + 그룹수 = **12 + ceil(이벤트수/5)**

**이벤트 20개 예시:**
- 최소: 4 + 4 = **8회**
- 최대: 12 + 4 = **16회**

**이벤트 40개 예시:**
- 최소: 4 + 8 = **12회**
- 최대: 12 + 8 = **20회**

---

### 3. 파일 분석 (업로드된 파일)
**파일**: `data-generator/src/api/services/file-analyzer.ts`

#### 단일 파일 분석:
- 호출 횟수: **파일당 1회**
- 모델: 사용자 설정 또는 기본 모델
- max_tokens: `4000` (기본값, `FILE_ANALYSIS_MAX_TOKENS` 환경변수)
- 지원 파일:
  - 텍스트 파일 (.txt, .md, .json, .yaml, .csv)
  - 이미지 파일 (.png, .jpg, .jpeg, .gif, .webp)
  - PDF 파일 (.pdf)

#### 다중 파일 분석 (Combined Insights):
- 개별 분석: **파일 수 × 1회**
- 통합 분석: **1회** (모든 개별 분석 결과를 통합)
- 총 호출: **파일 수 + 1회**

#### 예상 API 호출 수:
- 파일 1개: 1 + 1 = **2회**
- 파일 3개: 3 + 1 = **4회**
- 파일 5개 (최대): 5 + 1 = **6회**

---

### 4. 데이터 생성
**파일**: `data-generator/src/data-generator.ts`

데이터 생성 단계에서는 **AI API를 직접 호출하지 않습니다**.
AI 분석 결과를 바탕으로 로컬에서 Faker.js를 사용하여 데이터를 생성합니다.

---

## 워크플로우별 API 호출

### 워크플로우 1: 이벤트 Taxonomy만 생성
**단계**: 산업/시나리오 입력 → Excel 생성

**API 호출:**
- Stage 1: 1회
- Stage 2: ceil(이벤트수/3)회
- Stage 3: 1회
- 파일 분석 (선택): 파일수 + 1회

**총 호출 수 (파일 없음):**
- 이벤트 20개: **9회**
- 이벤트 40개: **16회**
- 이벤트 60개: **22회**

**총 호출 수 (파일 3개 포함):**
- 이벤트 20개: 9 + 4 = **13회**
- 이벤트 40개: 16 + 4 = **20회**

---

### 워크플로우 2: AI 분석만 (Excel → 전략 분석)
**단계**: Excel 업로드 → AI 분석 → 분석 Excel 다운로드

**API 호출:**
- Phase 1: 1회
- Phase 1.5 (리텐션): 1회 + 검증 (0~4회)
- Phase 1.5a (트랜잭션): 1회
- Phase 1.6 (시퀀스): 1회 + 검증 (0~4회)
- Phase 2 (그룹별): ceil(이벤트수/5)회
- 파일 분석 (선택): 파일수 + 1회

**총 호출 수 (검증 성공, 파일 없음):**
- 이벤트 20개: 4 + 4 = **8회**
- 이벤트 40개: 4 + 8 = **12회**

**총 호출 수 (검증 실패, 파일 3개):**
- 이벤트 20개: 12 + 4 + 4 = **20회**
- 이벤트 40개: 12 + 8 + 4 = **24회**

---

### 워크플로우 3: 전체 프로세스 (처음부터 끝까지)
**단계**: 산업/시나리오 입력 → Excel 생성 → AI 분석 → 데이터 생성

**API 호출:**
- Excel 생성: 2 + ceil(이벤트수/3)회
- AI 분석: 4 + ceil(이벤트수/5) + 검증(0~8회)
- 파일 분석 (선택): 파일수 + 1회

**총 호출 수 (검증 성공, 파일 없음):**
- 이벤트 20개: 9 + 8 = **17회**
- 이벤트 40개: 16 + 12 = **28회**
- 이벤트 60개: 22 + 16 = **38회**

**총 호출 수 (검증 실패, 파일 3개):**
- 이벤트 20개: 9 + 16 + 4 = **29회**
- 이벤트 40개: 16 + 20 + 4 = **40회**

---

## 비용 예측

### Claude API 요금 (2025년 기준)

#### Claude Sonnet 4.5 (claude-sonnet-4-20250514)
- Input: $3 / 1M tokens
- Output: $15 / 1M tokens

#### Claude Haiku 4.5 (claude-haiku-4-5) - 검증용
- Input: $0.80 / 1M tokens
- Output: $4 / 1M tokens

### 토큰 사용량 추정

#### 평균 토큰 사용량 (실제 사용 기준):
- **Taxonomy 생성 Stage 1**: ~2,000 input + ~3,000 output = 5,000 tokens
- **Taxonomy 생성 Stage 2 (배치당)**: ~1,500 input + ~2,000 output = 3,500 tokens
- **Taxonomy 생성 Stage 3**: ~1,000 input + ~1,500 output = 2,500 tokens
- **AI 분석 Phase 1**: ~3,000 input + ~4,000 output = 7,000 tokens
- **AI 분석 Phase 1.5**: ~2,000 input + ~1,500 output = 3,500 tokens
- **AI 분석 Phase 1.5a**: ~2,500 input + ~1,000 output = 3,500 tokens
- **AI 분석 Phase 1.6**: ~2,500 input + ~2,000 output = 4,500 tokens
- **AI 분석 Phase 2 (그룹당)**: ~2,000 input + ~2,500 output = 4,500 tokens
- **검증 (Validator)**: ~1,500 input + ~500 output = 2,000 tokens (Haiku)
- **검증 (Fixer)**: ~1,500 input + ~1,000 output = 2,500 tokens (Haiku)
- **파일 분석 (파일당)**: ~1,000 input + ~500 output = 1,500 tokens
- **파일 통합 분석**: ~2,000 input + ~1,000 output = 3,000 tokens

### 워크플로우별 예상 비용

#### 워크플로우 1: Taxonomy만 생성 (이벤트 40개, 파일 없음)
- Stage 1: 5,000 tokens
- Stage 2: 14배치 × 3,500 = 49,000 tokens
- Stage 3: 2,500 tokens
- **총 토큰**: ~56,500 tokens
- **Input**: ~22,000 tokens × $3/1M = **$0.066**
- **Output**: ~34,500 tokens × $15/1M = **$0.518**
- **총 비용**: **약 $0.58** (약 800원)

#### 워크플로우 2: AI 분석만 (이벤트 40개, 파일 3개, 검증 성공)
- Phase 1: 7,000 tokens
- Phase 1.5: 3,500 tokens
- Phase 1.5a: 3,500 tokens
- Phase 1.6: 4,500 tokens
- Phase 2: 8그룹 × 4,500 = 36,000 tokens
- 파일 분석: 3 × 1,500 + 3,000 = 7,500 tokens
- **총 토큰**: ~62,000 tokens
- **Input**: ~26,000 tokens × $3/1M = **$0.078**
- **Output**: ~36,000 tokens × $15/1M = **$0.540**
- **총 비용**: **약 $0.62** (약 850원)

#### 워크플로우 2: AI 분석만 (검증 실패 시)
- 위 비용 + 검증 비용 (Haiku):
  - 2개 검증 × (3회 재시도 × 2,000 tokens) = 12,000 tokens (Haiku)
  - 2개 Fixer × (3회 재시도 × 2,500 tokens) = 15,000 tokens (Haiku)
- **추가 Input**: ~16,000 tokens × $0.80/1M = **$0.013**
- **추가 Output**: ~11,000 tokens × $4/1M = **$0.044**
- **총 비용**: $0.62 + $0.057 = **약 $0.68** (약 930원)

#### 워크플로우 3: 전체 프로세스 (이벤트 40개, 파일 3개, 검증 성공)
- Taxonomy 생성: $0.58
- AI 분석: $0.62
- **총 비용**: **약 $1.20** (약 1,650원)

#### 워크플로우 3: 전체 프로세스 (검증 실패 시)
- Taxonomy 생성: $0.58
- AI 분석 (검증 포함): $0.68
- **총 비용**: **약 $1.26** (약 1,730원)

### 대규모 사용 예시

#### 이벤트 100개 + 파일 5개 + 전체 프로세스 + 검증 실패
- **Taxonomy 생성**:
  - Stage 1: 5,000 tokens
  - Stage 2: 34배치 × 3,500 = 119,000 tokens
  - Stage 3: 2,500 tokens
  - 소계: ~126,500 tokens → **$1.43**

- **AI 분석**:
  - Phase 1~1.6: ~18,500 tokens
  - Phase 2: 20그룹 × 4,500 = 90,000 tokens
  - 검증: ~27,000 tokens (Haiku)
  - 파일: 5 × 1,500 + 3,000 = 10,500 tokens
  - 소계: ~119,000 tokens (Sonnet) + 27,000 (Haiku) → **$1.49 + $0.14**

- **총 비용**: **약 $3.06** (약 4,200원)

---

## 비용 최적화 팁

### 1. 모델 선택 최적화
현재 모든 주요 분석에 Sonnet 4.5를 사용하고 있습니다. 용도별로 모델을 분리하면 비용을 절감할 수 있습니다:

#### 추천 모델 전략:
- **복잡한 분석** (Phase 1, Stage 1): **Sonnet 4.5** 유지
- **단순 반복 작업** (Stage 2 배치, Phase 2 그룹): **Haiku 4.5**로 전환 가능
  - 비용: 1/4 수준 ($15 → $4 per 1M output tokens)
  - 잠재적 절감: 약 40-50%

#### 구현 방법:
```typescript
// data-generator/.env
DATA_AI_MODEL=claude-sonnet-4-20250514  # 주요 분석용
VALIDATION_MODEL_TIER=fast  # Haiku 사용 (검증용)
EXCEL_ANTHROPIC_MODEL=claude-haiku-4-5  # Taxonomy Stage 2용 (선택)
```

### 2. 이벤트 수 제어
- **간단한 서비스**: 10-20개 이벤트 → 비용: ~$0.30
- **표준 서비스**: 20-40개 이벤트 → 비용: ~$0.60-1.20
- **복잡한 서비스**: 40-60개 이벤트 → 비용: ~$1.50-2.00
- **매우 복잡**: 60-100개 이벤트 → 비용: ~$2.50-4.00

→ 실제 필요보다 많은 이벤트를 생성하지 않도록 주의

### 3. 파일 분석 최적화
- **파일 크기 제한**: 큰 PDF/이미지는 토큰 사용량 증가
- **파일 수 최소화**: 핵심 문서만 업로드 (현재 최대 5개 제한)
- **텍스트 파일 선호**: 이미지/PDF보다 토큰 효율적

### 4. 검증 레벨 조정
```typescript
// 빠른 개발 시: fast (Haiku)
VALIDATION_MODEL_TIER=fast

// 프로덕션 품질: balanced (Sonnet)
VALIDATION_MODEL_TIER=balanced
```

- **fast (Haiku)**: 비용 1/4, 정확도 약간 낮음
- **balanced (Sonnet)**: 비용 높지만 정확도 최고

### 5. 배치 처리 효율화
현재 Stage 2에서 3개씩 배치 처리합니다:
- **배치 크기 증가** (3 → 5): API 호출 수 감소, 단 응답 잘림 위험
- **배치 크기 감소** (3 → 2): API 호출 수 증가, 안정성 향상

→ 현재 3개가 최적 균형

### 6. 캐싱 전략 (향후 구현 가능)
- 동일한 산업/시나리오 조합은 결과 캐싱
- Redis/Postgres에 AI 분석 결과 저장
- 재사용 시 API 호출 0회

---

## 월간 비용 예측

### 사용 패턴별 월 예상 비용

#### 개인 사용자 (월 10회 생성)
- 평균 이벤트 30개
- 워크플로우 3 사용
- **월 비용**: 10회 × $0.90 = **$9.00** (약 12,000원)

#### 소규모 팀 (월 50회 생성)
- 평균 이벤트 40개
- 워크플로우 2, 3 혼용
- **월 비용**: 50회 × $1.00 = **$50.00** (약 68,000원)

#### 중규모 팀 (월 200회 생성)
- 평균 이벤트 50개
- 전체 워크플로우 사용
- **월 비용**: 200회 × $1.50 = **$300.00** (약 410,000원)

#### 대규모 기업 (월 1000회 생성)
- 평균 이벤트 60개
- 다양한 워크플로우
- **월 비용**: 1000회 × $2.00 = **$2,000.00** (약 2,750,000원)

---

## 환경 변수 설정 가이드

### 비용 최적화를 위한 권장 설정

```bash
# data-generator/.env

# 주요 AI 모델 (전략 분석용) - 품질 중요
DATA_AI_MODEL=claude-sonnet-4-20250514

# Excel Taxonomy 생성 모델 - 비용 절감 가능
EXCEL_ANTHROPIC_MODEL=claude-haiku-4-5  # Haiku로 전환 시 40% 절감

# 검증 모델 등급
VALIDATION_MODEL_TIER=fast  # fast (Haiku) 또는 balanced (Sonnet)

# 커스텀 검증 모델 (선택)
# CUSTOM_VALIDATION_MODEL=claude-haiku-4-5

# 파일 분석 토큰 제한
FILE_ANALYSIS_MAX_TOKENS=4000  # 기본값, 필요시 증가 (비용↑)
```

### 시나리오별 추천 설정

#### 최저 비용 (품질 일부 희생):
```bash
DATA_AI_MODEL=claude-haiku-4-5
EXCEL_ANTHROPIC_MODEL=claude-haiku-4-5
VALIDATION_MODEL_TIER=fast
FILE_ANALYSIS_MAX_TOKENS=2000
```
→ 비용 절감: **약 70%**

#### 균형 (권장):
```bash
DATA_AI_MODEL=claude-sonnet-4-20250514
EXCEL_ANTHROPIC_MODEL=claude-haiku-4-5
VALIDATION_MODEL_TIER=fast
FILE_ANALYSIS_MAX_TOKENS=4000
```
→ 비용 절감: **약 30-40%**

#### 최고 품질:
```bash
DATA_AI_MODEL=claude-opus-4-5
EXCEL_ANTHROPIC_MODEL=claude-sonnet-4-20250514
VALIDATION_MODEL_TIER=balanced
FILE_ANALYSIS_MAX_TOKENS=8000
```
→ 비용 증가: **약 3-5배**

---

## 결론

### 핵심 요약
1. **평균 비용**: 워크플로우당 **$0.50 ~ $2.00** (약 700원 ~ 2,750원)
2. **주요 비용 요인**:
   - 이벤트 수 (가장 큰 영향)
   - 모델 선택 (Haiku vs Sonnet)
   - 파일 분석 (선택적)
   - 검증 재시도 (불확실성)

3. **최적화 우선순위**:
   1. 이벤트 수를 필요한 만큼만 생성
   2. Stage 2를 Haiku로 전환 (40% 절감)
   3. 파일 업로드 최소화
   4. fast 검증 모드 사용

4. **예상 ROI**:
   - 수동 작성 시간: **2-4시간**
   - AI 생성 시간: **2-5분**
   - 비용: **$1-2** (약 1,500-2,700원)
   - **시간당 가치**: 매우 높음 ✅

### 추가 모니터링 권장
- 실제 토큰 사용량 로깅 구현
- 월별 비용 대시보드 추가
- 사용자별 API 사용량 추적
